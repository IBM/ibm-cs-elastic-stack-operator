#
# Copyright 2020 IBM Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

general:
  environment: IBMCloudPrivate
  clusterDomain: cluster.local
  clusterName: mycluster
  ingressPort: 8443

image:
  pullPolicy: IfNotPresent
  pullSecret:
    enabled: false
    name: regcred

security:
  ca:
    keystore:
      password: changeme
    truststore:
      password: changeme
    # set to `external` to use existing CA stored in Kubernetes secret to generate certs
    origin: internal
    external:
      # the secret need to be in the same namespace as the chart release
      secretName: cluster-ca-cert
      # the Kubenetes field name (key) within the specified secret that stores CA cert
      certFieldName: tls.crt
      # the Kubenets field name (key) within the specified secret that stores CA private key
      keyFieldName: tls.key
  app:
    keystore:
      password: changeme
  tls:
    version: TLSv1.2

logstash:
  replicas: 1
  name: logstash
  heapSize: "512m"
  memoryLimit: "1024Mi"
  port: 5000
  image:
    repository: "quay.io/opencloudio/icp-logstash-oss"
    tag: "6.8.10-build.2"
    digest: "sha256:cc32db4699a72daae2b044949b11366737d5ea2b7e283a50e838cb9cbbfa689e"
  nodeSelector:
  tolerations: []
kibana:
  install: true
  replicas: 1
  name: kibana
  nodeSelector:
  tolerations: []
  # accepted values:
  # ingress or loadBalancer, defaults to loadBalancer
  access: loadBalancer
  ingress:
    # "/kibana" for managed service logging instance
    # sample value for custom ingress: "/tenantA/kibana"
    # no trailing /
    path: "/tenantA/kibana"
    # additional labels to facilitate link rendering in icp console
    labels:
      inmenu: "true"
      # if provided, the link will open in a new tab with the target value in the <a> tag
      target: "logging-sampleA"
    annotations:
  service:
    # additional labels to facilitate link rendering in icp console
    labels:
      inmenu: "true"
      # if provided, the link will open in a new tab with the target value in the <a> tag
      target: "logging-sampleA"
    # additional annotations to facilitate link rendering in icp console
    annotations:
      # display name that will show in the menu
      name: "Logging - Sample A"
      # provided by icp console
      id: "add-ons"
      # list of roles to be able to view TA in the menu
      roles: "ClusterAdministrator,Administrator,Operator,Viewer"
      # show link if user is in any of the teams
      # ui.icp.ibm.com/tenant:
  internal: 5601
  # port to access the kibana instance from outside the cluster
  # only used when ingress set to loadBalancer
  external: 31601
  # maximum old space size (in MB) of the V8 Javascript engine
  maxOldSpaceSize: "1536"
  memoryLimit: "2048Mi"
  image:
    repository: quay.io/opencloudio/icp-kibana-oss
    tag: 6.8.10-build.2
    digest: "sha256:4a5b398f4c6f725282e1189e326078e1245db24144e2892c6abc969dc1855c8c"
  init:
    resources:
      limits:
        memory: 256Mi
      requests:
        memory: 64Mi
  initImage:
    repository: "quay.io/opencloudio/curl"
    tag: "4.2.0-build.6"
    digest: "sha256:90256103fbff2b68202d1bebc57481f337f4cf397cc126c084d0e29f9ef6c11f"
  routerImage:
    repository: "quay.io/opencloudio/icp-management-ingress"
    tag: "2.5.5"
    digest: "sha256:0070e99691123f2437f5d5b1422f9d0b8eec5746f72e656d1fc9e7947a56e00e"
    resources:
      limits:
        memory: 256Mi
      requests:
        memory: 64Mi
  security:
    authc:
      enabled: false
      # accepted values: icp
      # what it does: redirects to icp login page first
      provider: icp
    authz:
      enabled: false
      # accepted values: icp
      # what it does: only allow request to pass if user
      # have access to the required namespaces
      # that the current user has access to
      # requires authc.enabled = true and authc.provider = icp
      provider: icp
      icp:
        # 1. user is allowed to access the kibana ingress
        #    if namespaces granted to user are listed below
        # 2. when the list below is empty, only cluster admin
        #    can access this kibana ingress
        authorizedNamespaces:
          - tenantadev
          - tenantatest
          - tenantaprod

filebeat:
  name: filebeat-ds
  resources:
    limits:
      memory: 256Mi
    requests:
      memory: 64Mi
  image:
    repository: "quay.io/opencloudio/icp-filebeat-oss"
    tag: "6.8.10-build.2"
    digest: "sha256:a98e22356c1e510cff4f7e3c51d744bccc8d035e39db869356f2fd2e7b6988a8"
  scope:
    nodes: {}
    namespaces: []
  tolerations: []
  registryHostPath: "/var/lib/icp/logging/filebeat-registry/{{ .Release.Name }}"
  # accepted values: text, json
  # what it does: parses the log data as json or text
  logFormat: text
elasticsearch:
  name: "elasticsearch"
  internalPort: 9300
  image:
    repository: "quay.io/opencloudio/icp-elasticsearch-oss"
    tag: "6.8.10-build.2"
    digest: "sha256:70e3a69ae5d66e10d32d88f2d7656a7d649bc3aa951b79f6b5a7504eec703a4e"
  pkiInitImage:
    repository: "quay.io/opencloudio/logging-pki-init"    
    tag: "2.3.0-build.3"
    digest: "sha256:d73cbc2895486c425bde39497b10e00fd45b550e4953eb8d3e04c1ac3936b4a8"
    resources:
      limits:
        memory: 512Mi
      requests:
        memory: 64Mi
  initImage:
    repository: "quay.io/opencloudio/icp-initcontainer"
    tag: "1.0.0-build.7"
    digest: "sha256:78c7914777de08064511033fc1065f3b1d0f593f59b8147230cd2f9c2405abd0"
  routerImage:
    repository: "quay.io/opencloudio/icp-management-ingress"
    digest: "sha256:0070e99691123f2437f5d5b1422f9d0b8eec5746f72e656d1fc9e7947a56e00e"
    tag: "2.5.5"
    resources:
       limits:
         memory: 256Mi
       requests:
         memory: 64Mi
  security:
    authc:
      # accepted values: true
      enabled: true
      # accepted values: nginx
      # what it does: mtls authz with account rbac
      provider: nginx
    authz:
      enabled: false
      # accepted values: icp
      # what it does: filter log content by the namespace
      # that the current user has access to
      provider: icp

  client:
    restPort: 9200

  data:
    name: data
    # Set to the # of management (or master, if no mgmt) nodes
    replicas: 2
    heapSize: 4000m
    memoryLimit: 7000M
    antiAffinity: hard
    tolerations: []
    nodeSelector:
    storage:
      # When true will expect a PersistentVolume
      persistent: true
      # Set to true if you are using GlusterFS or other dynamic provisioner
      useDynamicProvisioning: false
      # If not using dynamic provisioning, you can use selectors to refine the binding process.
      # These are IGNORED if using dynamic provisioning.
      selector:
        label: ""
        value: ""
      # 30Gi is not the recommended size, but rather a small default.
      # It will match much larger drives as well.
      size: 30Gi
      accessModes:
        - ReadWriteOnce
      ## Specify the storageClass name you want to use
      ## If you don't specify a storageClass name it will use the default
      storageClass: ""

curator:
  name: log-curator
  resources:
    limits:
      memory: 256Mi
    requests:
      memory: 64Mi
  image:
    repository: "quay.io/opencloudio/indices-cleaner"
    tag: "1.3.0-build.2"
    digest: "sha256:59e1eae63fd6039245ee2172c474994275cf0aa41a7856783d6d48e729ccacc5"
  # runs at 23:30 UTC daily
  schedule: "30 23 * * *"
  nodeSelector:
  tolerations: []
  app:
    unit: days
    count: 1
  monitoring:
    unit: days
    count: 7
  watcher:
    unit: days
    count: 1
  va:
    unit: days
    count: 90
  mapp:
    unit: days
    count: 2
  auditLog:
    unit: days
    count: 1

upgrade:
  elasticsearch:
    # set to true if data from old version need to be imported
    importData: true
    # if set to true, a copy of existing data in old format will be left intact
    # under pv-mount/nodes (/usr/share/elasticsearch/data/nodes)
    # this allows data (up to point of upgrade) to be restored when rolling back
    retainOldData: true
